from __future__ import annotations

from datetime import datetime
from typing import Dict, Any, List
import re

# ìš•ì„¤ / ê°•í•œ í‘œí˜„ (ê³¼ì œ/ì—°êµ¬ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
SWEAR_WORDS = [
    "ì‹œë°œ", "ì”¨ë°œ", "ã……ã…‚", "ã…†ã…‚", "ã…‚ã……", "ë³‘ì‹ ", "ë¸…ì‹ ", "ì¡´ë‚˜",
    "ê°œìƒˆë¼", "ìƒˆë¼", "ì§€ë„", "êº¼ì ¸", "ë¯¸ì¹œ", "ë˜ë¼ì´", "ê°œê°™", "ì—¼ë³‘",
]

# ê²Œì„ ê´€ë ¨ í‚¤ì›Œë“œ (ë¡¤/ë­í¬/pcë°© ë“±)
GAME_WORDS = [
    "ë¡¤", "ë¡¤ì²´", "ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ", "ë°œë¡œë€íŠ¸", "ë°œë¡œ",
    "ë­í¬", "í‹°ì–´", "ì†”ë­", "ë“€ì˜¤", "ì •ê¸€", "íƒ‘", "ë¯¸ë“œ", "ì›ë”œ", "ì„œí¿",
    "í", "ëŒ€ê¸°ì¤‘", "pcë°©", "í”¼ì‹œë°©", "ê²Œì„", "ë°°ê·¸", "í”¼íŒŒ",
]

# ëŒ€í™” ì£¼ì œ ë¶„ë¥˜ìš© í‚¤ì›Œë“œ
TOPIC_KEYWORDS = {
    "daily_life": ["ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ë­í•´", "ë­í•¨", "ë°¥", "ì‹ì‚¬", "ì»¤í”¼", "ë‚ ì”¨", "ì§‘ì—"],
    "emotion": ["ê¸°ë¶„", "ëŠë‚Œ", "ìŠ¬í¼", "ê¸°ë»", "í™”ë‚˜", "ì§œì¦", "í–‰ë³µ", "ìš°ìš¸", "ì‚¬ë‘", "ì¢‹ì•„", "ì‹«ì–´"],
    "planning": ["ê³„íš", "ì•½ì†", "ì–¸ì œ", "ì–´ë””ì„œ", "ë§Œë‚˜", "ì—¬í–‰", "ì£¼ë§ì—", "ë‹¤ìŒì—", "ê°™ì´"],
    "development": ["ì½”ë”©", "ê°œë°œ", "í”„ë¡œì íŠ¸", "ì„œë²„", "í´ë¼", "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸", "ë²„ê·¸", "ê¹ƒ", "github", "íŒŒì´ì¬", "ìë°”"],
    "school": ["ê³¼ì œ", "ìˆ˜ì—…", "êµìˆ˜ë‹˜", "ì‹œí—˜", "ë°œí‘œ", "íŒ€í”Œ", "ë„ì„œê´€", "í•™ì "],
    "hobby": ["ì·¨ë¯¸", "ì˜í™”", "ë“œë¼ë§ˆ", "ìŒì•…", "ì±…", "ìš´ë™", "ê²Œì„", "ìœ íŠœë¸Œ", "ë„·í”Œë¦­ìŠ¤"],
    "meme": ["ã…‹ã…‹", "ã…ã…", "ë ˆì „ë“œ", "ì‹¤í™”", "ì˜¤íˆë ¤", "í¼ ë¯¸ì³¤ë‹¤", "ê°€ë³´ìê³ ", "í‚¹ë°›ë„¤"],
    "info_request": ["ì•Œë ¤ì¤˜", "ì•Œë ¤ì£¼ì„¸ìš”", "ë­ì•¼", "ë­”ë°", "ì–´ë–»ê²Œ", "ì™œ"],
    "economy": ["ì£¼ì‹", "ì½”ì¸", "ëˆ", "ê²½ì œ", "ê°€ê²©", "ë¹„ìš©", "íˆ¬ì", "ì›”ê¸‰"],
    "romance": ["ì—°ì• ", "ì†Œê°œíŒ…", "ë°ì´íŠ¸", "ë‚¨ì¹œ", "ì—¬ì¹œ", "ì¸"],
}


def _get_time_bucket(dt: datetime) -> str:
    """
    ëŒ€ëµì ì¸ í™œë™ ì‹œê°„ëŒ€ ë²„í‚·:
    - night : 00~06ì‹œ
    - morning : 06~12ì‹œ
    - afternoon : 12~18ì‹œ
    - evening : 18~24ì‹œ
    """
    h = dt.hour
    if 0 <= h < 6:
        return "night"
    if 6 <= h < 12:
        return "morning"
    if 12 <= h < 18:
        return "afternoon"
    return "evening"


def _count_words(text: str) -> int:
    """
    ì•„ì£¼ ë‹¨ìˆœí•œ ë‹¨ì–´ ìˆ˜ ì„¸ê¸°:
    - ê³µë°± ê¸°ì¤€ìœ¼ë¡œ split
    - í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œë„ ëŒ€ëµì ì¸ â€œí† ë§‰ ìˆ˜â€ ëŠë‚Œìœ¼ë¡œ ì‚¬ìš©
    """
    if not text:
        return 0
    # ì—°ì† ê³µë°±ì„ ìë™ìœ¼ë¡œ ë¬´ì‹œí•´ì£¼ë¯€ë¡œ ê·¸ëƒ¥ split() ì‚¬ìš©
    return len(text.split())


def _tokenize_basic(text: str) -> List[str]:
    """
    ê°„ë‹¨í•œ í† í° ë‚˜ëˆ„ê¸° (ìƒìœ„ ë‹¨ì–´ ì§‘ê³„ìš©).
    - ì•ŒíŒŒë²³/ìˆ«ì/í•œê¸€ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ê³µë°± ì²˜ë¦¬
    """
    if not text:
        return []
    cleaned = re.sub(r"[^0-9a-zA-Zê°€-í£\s]", " ", text)
    tokens = [t for t in cleaned.split() if t.strip()]
    return tokens


def extract_kakao_features(parsed: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì¹´ì¹´ì˜¤í†¡ íŒŒì‹± ê²°ê³¼(dict)ë¥¼ ë°›ì•„,
    - ë°œí™”ì ë¹„ìœ¨
    - ì•¼í–‰ì„± ë¹„ìœ¨
    - ì§ˆë¬¸/ê°íƒ„/ì´ëª¨í‹°ì½˜ ë¹„ìœ¨
    - ìš•ì„¤/ê²Œì„ ê´€ë ¨ ëŒ€í™” ë¹„ìœ¨
    - í‰ê·  ë‹µì¥ ì‹œê°„(ë¶„)
    - âœ… ë‚´ê°€ ì“´ ë‹¨ì–´ ìˆ˜ / ë°© ì „ì²´ ë‹¨ì–´ ìˆ˜
    - âœ… ì‹œê°„ëŒ€ë³„ í™œë™ ë¹„ìœ¨, ìƒìœ„ ë‹¨ì–´/ì´ëª¨í‹°ì½˜, ìƒ˜í”Œ ë©”ì‹œì§€
    ë“±ì„ ê³„ì‚°í•œë‹¤.
    """
    messages: List[Dict[str, Any]] = parsed.get("messages", [])
    meta = parsed.get("meta", {})
    user_sender = meta.get("user_sender")

    total_messages = len(messages)
    if total_messages == 0:
        return {
            "kakao_message_count": 0,
            "kakao_sender_count": 0,
            # ë‹¨ì–´ ìˆ˜ 0ìœ¼ë¡œ ì„¸íŒ… (ì•ˆì „)
            "word_count": 0,
            "user_word_count": 0,
            "room_word_count": 0,
        }

    # ë°œí™”ìë³„ ê°œìˆ˜
    sender_counts: Dict[str, int] = {}
    for msg in messages:
        s = msg["sender"]
        sender_counts[s] = sender_counts.get(s, 0) + 1

    # ê°€ì¥ ë§ì´ ë§í•œ ì‚¬ëŒì„ userë¡œ ê°€ì • (fallback)
    if not user_sender:
        user_sender = max(sender_counts, key=sender_counts.get)

    user_msgs = [m for m in messages if m["sender"] == user_sender]
    other_msgs = [m for m in messages if m["sender"] != user_sender]

    user_msg_count = len(user_msgs)
    user_msg_ratio = user_msg_count / total_messages if total_messages > 0 else 0.0

    # âœ… ë‹¨ì–´ ìˆ˜: ë‚´ ë©”ì‹œì§€ ê¸°ì¤€ + ë°© ì „ì²´ ê¸°ì¤€
    user_word_count = sum(_count_words(m["text"]) for m in user_msgs)
    room_word_count = sum(_count_words(m["text"]) for m in messages)

    # í‰ê·  ê¸€ì ìˆ˜ (ë‚´ ë©”ì‹œì§€ ê¸°ì¤€)
    if user_msg_count > 0:
        avg_user_len = sum(len(m["text"]) for m in user_msgs) / user_msg_count
    else:
        avg_user_len = 0.0

    # ì‹œê°„ëŒ€/ìƒ˜í”Œ/ìƒìœ„ ë‹¨ì–´/ì´ëª¨í‹°ì½˜ ì§‘ê³„ìš©
    bucket_counts = {"night": 0, "morning": 0, "afternoon": 0, "evening": 0}
    night_samples: List[str] = []
    game_samples: List[str] = []
    word_freq: Dict[str, int] = {}
    emoji_freq: Dict[str, int] = {}

    # ì•¼í–‰ì„± ë¹„ìœ¨ (ìê¸° ë©”ì‹œì§€ ì¤‘ ë°¤/ì‹¬ì•¼ ë¹„ìœ¨)
    night_count = 0

    # ì§ˆë¬¸/ê°íƒ„/ì´ëª¨í‹°ì½˜/ìš•ì„¤/ê²Œì„ ê´€ë ¨ ë¹„ìœ¨
    def is_question(text: str) -> bool:
        return "?" in text

    def is_exclamation(text: str) -> bool:
        return "!" in text

    EMO_PATTERNS = ["ã…‹ã…‹", "ã…ã…", "ã… ã… ", "ã… ", "ã…œã…œ", "ã…œ", "^^", "â¤ï¸", "â™¥", "ã…‹", "ã…"]

    def emoji_like_ratio(text: str) -> float:
        if not text:
            return 0.0
        count = 0
        for p in EMO_PATTERNS:
            count += text.count(p)
        # ë„ˆë¬´ ë§ì´ ë‚˜ì™€ë„ ìµœëŒ€ 1.0ê¹Œì§€ë§Œ
        return min(1.0, count / max(1, len(text)))

    def contains_any(text: str, patterns: List[str]) -> bool:
        return any(p in text for p in patterns)

    q_cnt = 0
    e_cnt = 0
    emoji_ratios: List[float] = []
    swear_msg_cnt = 0
    game_msg_cnt = 0
    night_game_msg_cnt = 0
    topic_counts = {topic: 0 for topic in TOPIC_KEYWORDS}

    for m in user_msgs:
        t = m["text"]
        bucket = _get_time_bucket(m["timestamp"])
        bucket_counts[bucket] = bucket_counts.get(bucket, 0) + 1

        # ì•¼ê°„ ë©”ì‹œì§€ ì¹´ìš´íŠ¸
        if bucket == "night":
            night_count += 1
            if len(night_samples) < 3 and t:
                night_samples.append(t)

        # ì§ˆë¬¸/ê°íƒ„/ì´ëª¨í‹°ì½˜
        if is_question(t):
            q_cnt += 1
        if is_exclamation(t):
            e_cnt += 1

        emoji_ratios.append(emoji_like_ratio(t))

        # ìš•ì„¤/ê²Œì„
        has_swear = contains_any(t, SWEAR_WORDS)
        has_game = contains_any(t, GAME_WORDS)

        if has_swear:
            swear_msg_cnt += 1
        if has_game:
            game_msg_cnt += 1
            if len(game_samples) < 3 and t:
                game_samples.append(t)
            if bucket == "night":
                night_game_msg_cnt += 1
        
        # ì£¼ì œ ë¶„ì„
        for topic, keywords in TOPIC_KEYWORDS.items():
            if contains_any(t, keywords):
                topic_counts[topic] = topic_counts.get(topic, 0) + 1

        # ìƒìœ„ ë‹¨ì–´ ìˆ˜ì§‘
        for w in _tokenize_basic(t):
            w_lower = w.lower()
            # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´/ìˆ«ìë§Œ ìˆëŠ” í† í°ì€ ì œì™¸ (ë…¸ì´ì¦ˆ ê°ì†Œìš©)
            if len(w_lower) < 2:
                continue
            if w_lower.isdigit():
                continue
            word_freq[w_lower] = word_freq.get(w_lower, 0) + 1

        # ìƒìœ„ ì´ëª¨í‹°ì½˜/ë°˜ì‘ ìˆ˜ì§‘
        for p in EMO_PATTERNS:
            c = t.count(p)
            if c > 0:
                emoji_freq[p] = emoji_freq.get(p, 0) + c

    if user_msg_count > 0:
        user_night_ratio = night_count / user_msg_count
        user_question_ratio = q_cnt / user_msg_count
        user_exclamation_ratio = e_cnt / user_msg_count
        user_emoji_ratio = sum(emoji_ratios) / len(emoji_ratios) if emoji_ratios else 0.0
        user_swear_msg_ratio = swear_msg_cnt / user_msg_count
        user_game_msg_ratio = game_msg_cnt / user_msg_count
        user_night_game_msg_ratio = (
            night_game_msg_cnt / game_msg_cnt if game_msg_cnt > 0 else 0.0
        )
    else:
        user_night_ratio = 0.0
        user_question_ratio = 0.0
        user_exclamation_ratio = 0.0
        user_emoji_ratio = 0.0
        user_swear_msg_ratio = 0.0
        user_game_msg_ratio = 0.0
        user_night_game_msg_ratio = 0.0

    # ì‹œê°„ëŒ€ ë¹„ìœ¨ ë° ìµœë‹¤ í™œë™ ì‹œê°„ëŒ€
    if user_msg_count > 0:
        user_time_ratio_night = bucket_counts["night"] / user_msg_count
        user_time_ratio_morning = bucket_counts["morning"] / user_msg_count
        user_time_ratio_afternoon = bucket_counts["afternoon"] / user_msg_count
        user_time_ratio_evening = bucket_counts["evening"] / user_msg_count
        most_active_period = max(bucket_counts, key=bucket_counts.get)
    else:
        user_time_ratio_night = 0.0
        user_time_ratio_morning = 0.0
        user_time_ratio_afternoon = 0.0
        user_time_ratio_evening = 0.0
        most_active_period = None

    # ì£¼ì œ ë¹„ìœ¨ ê³„ì‚°
    user_topic_ratios = {}
    if user_msg_count > 0:
        for topic, count in topic_counts.items():
            user_topic_ratios[f"topic_{topic}_ratio"] = count / user_msg_count

    # ìƒìœ„ ë‹¨ì–´/ì´ëª¨í‹°ì½˜ ì •ë ¬
    def _top_n(d: Dict[str, int], n: int) -> List[str]:
        return [k for k, _ in sorted(d.items(), key=lambda x: x[1], reverse=True)[:n]]

    top_words = _top_n(word_freq, 10)
    top_emojis = _top_n(emoji_freq, 5)

    # === ë‚´ê°€ ìì£¼ ì“°ëŠ” ë§ ì˜ˆì‹œ (ì´ëª¨í‹°ì½˜/í”Œë ˆì´ìŠ¤í™€ë” ì œì™¸) ===
    common_samples: List[str] = []
    MAX_SAMPLES = 5

    for w in top_words:
        if len(common_samples) >= MAX_SAMPLES:
            break
        for m in user_msgs:
            t = m["text"] or ""

            # ğŸ”¥ Kakao ë‚´ë³´ë‚´ê¸°ì—ì„œ ì´ëª¨í‹°ì½˜ì€ "ì´ëª¨í‹°ì½˜" ê°™ì€ í…ìŠ¤íŠ¸ë¡œ ë“¤ì–´ì˜¤ë¯€ë¡œ ê±¸ëŸ¬ì¤€ë‹¤
            if "ì´ëª¨í‹°ì½˜" in t:
                continue

            # (ì˜µì…˜) ë„ˆë¬´ ì§§ì€ ê±´ ì œì™¸í•˜ê³  ì‹¶ìœ¼ë©´ ìœ ì§€, ì•„ë‹ˆë¼ë©´ ì§€ì›Œë„ ë¨
            if len(t.strip()) < 2:
                continue

            if w in t and t not in common_samples:
                common_samples.append(t)
                if len(common_samples) >= MAX_SAMPLES:
                    break


    # í‰ê·  ë‹µì¥ ì‹œê°„ (other -> user)
    reply_deltas: List[float] = []
    if user_msg_count > 0 and other_msgs:
        n = len(messages)
        for i, msg in enumerate(messages):
            if msg["sender"] == user_sender:
                continue
            for j in range(i + 1, n):
                if messages[j]["sender"] == user_sender:
                    delta = messages[j]["timestamp"] - msg["timestamp"]
                    minutes = delta.total_seconds() / 60.0
                    # í•˜ë£¨ ì´ìƒ ì°¨ì´ë‚˜ë©´ ë‹µì¥ì´ë¼ê³  ë³´ì§€ ì•Šê³  ë²„ë¦¼
                    if 0 < minutes < 60 * 24:
                        reply_deltas.append(minutes)
                    break

    if reply_deltas:
        avg_reply_minutes = sum(reply_deltas) / len(reply_deltas)
    else:
        avg_reply_minutes = 0.0

    # 2. ì°¸ì—¬ì ìˆ˜ ë³´ì • ë°œí™”ëŸ‰ (talkativeness)
    sender_count = len(sender_counts)
    talkativeness = 0.0
    if sender_count > 0:
        # ë‚´ê°€ ë§í•œ ë¹„ìœ¨ / (1/n) -> nëª…ì´ ë™ë“±í•˜ê²Œ ë§í–ˆì„ ë•Œ ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë” ë§í–ˆëŠ”ê°€
        talkativeness = user_msg_ratio / (1 / sender_count)

    features: Dict[str, Any] = {
        "kakao_message_count": total_messages,
        "kakao_sender_count": len(sender_counts),

        "user_sender_name": user_sender,

        # âœ… ë‹¨ì–´ ìˆ˜ ê´€ë ¨
        # - word_count: "ë‚´ê°€ ì“´ ë‹¨ì–´ ìˆ˜" (MBTI/ì‹ ë¢°ë„ì—ì„œ ì‚¬ìš©í•  ê°’)
        # - user_word_count: ë‚´ê°€ ì“´ ë‹¨ì–´ ìˆ˜ (ë””ë²„ê·¸/í‘œì‹œìš©)
        # - room_word_count: ë°© ì „ì²´ ë‹¨ì–´ ìˆ˜ (ì°¸ê³ ìš©)
        "word_count": user_word_count,
        "user_word_count": user_word_count,
        "room_word_count": room_word_count,

        "user_message_ratio": user_msg_ratio,
        "talkativeness": talkativeness, # âœ… ì°¸ì—¬ì ìˆ˜ ë³´ì • ë°œí™”ëŸ‰
        "user_avg_chars_per_message": avg_user_len,
        "user_night_message_ratio": user_night_ratio,
        "user_question_ratio": user_question_ratio,
        "user_exclamation_ratio": user_exclamation_ratio,
        "user_emoji_ratio": user_emoji_ratio,
        "user_swear_msg_ratio": user_swear_msg_ratio,
        "user_game_msg_ratio": user_game_msg_ratio,
        "user_night_game_msg_ratio": user_night_game_msg_ratio,
        "avg_reply_minutes": avg_reply_minutes,

        # âœ… ì‹œê°„ëŒ€ ê´€ë ¨
        "user_time_ratio_night": user_time_ratio_night,
        "user_time_ratio_morning": user_time_ratio_morning,
        "user_time_ratio_afternoon": user_time_ratio_afternoon,
        "user_time_ratio_evening": user_time_ratio_evening,
        "user_most_active_period": most_active_period,

        # âœ… ìƒìœ„ ë‹¨ì–´/ì´ëª¨í‹°ì½˜ + ìƒ˜í”Œ ë©”ì‹œì§€
        "user_top_words": top_words,
        "user_top_emojis": top_emojis,
        "sample_night_messages": night_samples,
        "sample_game_messages": game_samples,
        "sample_common_messages": common_samples,
    }
    
    # ì£¼ì œ ë¹„ìœ¨ ì¶”ê°€
    features.update(user_topic_ratios)

    return features
