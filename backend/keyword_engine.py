from __future__ import annotations

from typing import Dict, Any
import os
import re
import random

from dotenv import load_dotenv
from openai import OpenAI

# ==============================
# í™˜ê²½ ë³€ìˆ˜(.env) ë¡œë“œ & í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ==============================
load_dotenv()

API_KEY = os.getenv("OPENAI_API_KEY")
GPT_MODEL_NAME = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")

if API_KEY:
    client = OpenAI(api_key=API_KEY)
else:
    client = None

print("[keyword_engine] API_KEY set:", bool(API_KEY), "client is None:", client is None)


# ==============================
# Dominant Aspect ê³„ì‚°
# ==============================
def choose_dominant_aspect(features: Dict[str, Any]) -> str:
    topic_ratios = {
        k.replace("topic_", "").replace("_ratio", ""): v
        for k, v in features.items()
        if k.startswith("topic_") and isinstance(v, (int, float))
    }

    dominant_topic = None
    if topic_ratios:
        dominant_topic_name, dominant_topic_ratio = max(
            topic_ratios.items(), key=lambda item: item[1]
        )
        dominant_topic = (dominant_topic_name, dominant_topic_ratio)

    candidates: list[tuple[str, float]] = []

    night = float(features.get("user_night_message_ratio", 0.0) or 0.0)
    if night >= 0.7:
        candidates.append(("night_owl", night))

    emoji = float(features.get("user_emoji_ratio", 0.0) or 0.0)
    if emoji >= 0.4:
        candidates.append(("emoji", emoji))

    game = float(features.get("user_game_msg_ratio", 0.0) or 0.0)
    if game >= 0.3:
        candidates.append(("game", game))

    question = float(features.get("user_question_ratio", 0.0) or 0.0)
    if question >= 0.3:
        candidates.append(("questioner", question))

    swear = float(features.get("user_swear_msg_ratio", 0.0) or 0.0)
    if swear >= 0.1:
        candidates.append(("swear", swear))

    avg_reply = features.get("avg_reply_minutes", None)
    try:
        avg_reply_val = float(avg_reply) if avg_reply is not None else None
    except:
        avg_reply_val = None

    if avg_reply_val is not None:
        if avg_reply_val <= 10:
            score = 1.0 - max(0.0, min(avg_reply_val, 10.0)) / 10.0
            candidates.append(("fast_reply", score))
        elif avg_reply_val >= 60:
            norm = min(avg_reply_val, 180.0) - 60.0
            score = norm / 120.0
            candidates.append(("slow_reply", score))

    if dominant_topic and dominant_topic[1] >= 0.15:
        candidates.append(dominant_topic)

    if not candidates:
        return "neutral"

    return max(candidates, key=lambda x: x[1])[0]


# ==============================
# LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
# ==============================
def _build_label_prompt(mbti_result: Dict[str, Any], confidence: Dict[str, Any]) -> str:
    scores = mbti_result.get("scores", {})
    features = mbti_result.get("features", {})
    mbti_type = mbti_result.get("type", "XXXX")
    conf_score = confidence.get("score", 0)
    dominant = choose_dominant_aspect(features)

    prompt = f"""
ì—­í• : MBTI + ì¹´ì¹´ì˜¤í†¡ í–‰ë™ íŒ¨í„´ ê¸°ë°˜ì˜ ì°½ì˜ì ì¸ ìˆ˜ì‹ì–´ ìƒì„±ê¸°.

ì…ë ¥ ì •ë³´:
- MBTI: {mbti_type} (E:{scores.get("E")}, N:{scores.get("N")}, F:{scores.get("F")}, P:{scores.get("P")})
- ì£¼ìš” íŠ¹ì§•(Dominant Aspect): {dominant}
- ì‹ ë¢°ë„: {conf_score}

ìš”ì²­:
- ì‚¬ìš©ìì˜ íŠ¹ì§•ì„ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” 'í•œ ë‹¨ì–´ ìˆ˜ì‹ì–´ + MBTI' í˜•íƒœì˜ ë¼ë²¨ì„ **3ê°œ** ë§Œë“¤ì–´ë¼.
- ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¼ë¼:

label1: (ìˆ˜ì‹ì–´) (MBTI)
label2: (ìˆ˜ì‹ì–´) (MBTI)
label3: (ìˆ˜ì‹ì–´) (MBTI)

ì˜ˆ:
label1: ì•¼í–‰ì„± ENFP
label2: ì¹¼ë‹µëŸ¬ ENFP
label3: ê°ì„±íŒŒ ENFP

ê·œì¹™:
- ë°˜ë“œì‹œ í•œ ë‹¨ì–´ ìˆ˜ì‹ì–´ ì‚¬ìš©.
- í•œêµ­ì–´ ìˆ˜ì‹ì–´ ì‚¬ìš©.
- ë‹¤ë¥¸ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€.
- ë°˜ë“œì‹œ ìœ„ 3ì¤„ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥.
"""
    return prompt


# ==============================
# ìµœì¢… ë¼ë²¨ + í‚¤ì›Œë“œ ìƒì„±
# ==============================
def generate_label_with_llm(
    mbti_result: Dict[str, Any],
    confidence: Dict[str, Any],
) -> Dict[str, str]:

    mbti_type = mbti_result.get("type", "XXXX")
    fallback_label = f"ê¸°ë³¸í˜• {mbti_type}"
    fallback_keyword = "ê¸°ë³¸í˜•"

    if client is None:
        return {"label": fallback_label, "keyword": fallback_keyword}

    prompt = _build_label_prompt(mbti_result, confidence)

    model_for_chat = GPT_MODEL_NAME
    if model_for_chat.startswith("o3"):
        print("[keyword_engine] model is o3*, fallback gpt-4o-mini")
        model_for_chat = "gpt-4o-mini"

    try:
        completion = client.chat.completions.create(
            model=model_for_chat,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë°˜ë“œì‹œ label1, label2, label3 í˜•íƒœë¡œë§Œ ì¶œë ¥í•˜ë¼. "
                        "ì„¤ëª… ê¸ˆì§€. ë‹¤ë¥¸ ë¬¸ì¥ ê¸ˆì§€. í˜•ì‹ ë³€ê²½ ê¸ˆì§€."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=128,
            temperature=1.3,
            top_p=0.9,
        )

        raw_text = (completion.choices[0].message.content or "").strip()

        # ë¼ì¸ë³„ íŒŒì‹±
        lines = [l.strip() for l in raw_text.split("\n") if l.strip()]

        labels = []
        for line in lines:
            if line.lower().startswith("label"):
                parts = line.split(":", 1)
                if len(parts) == 2:
                    label = parts[1].strip()
                    labels.append(label)

        if not labels:
            print("[keyword_engine] parsing failed, fallback")
            return {"label": fallback_label, "keyword": fallback_keyword}

        # ğŸ¯ í›„ë³´ 3ê°œ ì¤‘ ëœë¤ 1ê°œ ì„ íƒ
        selected = random.choice(labels)

        # ì •ì œ
        cleaned = selected.replace('"', "").replace("'", "")
        cleaned = re.sub(r"\s+", " ", cleaned).strip()

        # keyword = MBTI ì•ë¶€ë¶„
        mbti_pattern = re.compile(r"\b[EI][NS][TF][PJ]\b")
        m = mbti_pattern.search(cleaned)
        if m:
            found_mbti = m.group(0)
            keyword_part = cleaned.replace(found_mbti, "").strip()
            final_label = f"{keyword_part} {mbti_type}"
        else:
            keyword_part = cleaned
            final_label = f"{cleaned} {mbti_type}"

        return {
            "label": final_label,
            "keyword": keyword_part,
        }

    except Exception as e:
        print(f"[keyword_engine] ERROR: {e}")
        return {"label": fallback_label, "keyword": fallback_keyword}
